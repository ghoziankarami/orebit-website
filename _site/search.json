[
  {
    "objectID": "posts/Welcome to Orebit/index.html",
    "href": "posts/Welcome to Orebit/index.html",
    "title": "Welcome to Orbit: Open-Source Geological Analysis Tools",
    "section": "",
    "text": "Orbit Geological Solutions develops open-source R Shiny applications that transform geological data analysis. Our mission: provide enterprise-level analytical tools without expensive licensing fees.\n\n\nTraditional geological software costs $20,000+ annually, creating barriers for: - Small exploration companies - Independent consultants - Geologists in developing regions - Educational institutions\n\n\n\n\n\nComplete geological data analysis platform\n\nInteractive 3D drillhole visualization\nAdvanced statistical analysis & EDA\nComprehensive QA/QC validation\nProfessional reporting tools\n\nTry Demo →\n\n\n\nProfessional geostatistical analysis with automated variogram modeling, kriging, and uncertainty quantification.\n\n\n\nStrategic mine planning with NPV optimization and constraint modeling."
  },
  {
    "objectID": "posts/Welcome to Orebit/index.html#professional-geological-analysis-accessible-to-everyone",
    "href": "posts/Welcome to Orebit/index.html#professional-geological-analysis-accessible-to-everyone",
    "title": "Welcome to Orbit: Open-Source Geological Analysis Tools",
    "section": "",
    "text": "Orbit Geological Solutions develops open-source R Shiny applications that transform geological data analysis. Our mission: provide enterprise-level analytical tools without expensive licensing fees.\n\n\nTraditional geological software costs $20,000+ annually, creating barriers for: - Small exploration companies - Independent consultants - Geologists in developing regions - Educational institutions\n\n\n\n\n\nComplete geological data analysis platform\n\nInteractive 3D drillhole visualization\nAdvanced statistical analysis & EDA\nComprehensive QA/QC validation\nProfessional reporting tools\n\nTry Demo →\n\n\n\nProfessional geostatistical analysis with automated variogram modeling, kriging, and uncertainty quantification.\n\n\n\nStrategic mine planning with NPV optimization and constraint modeling."
  },
  {
    "objectID": "posts/Welcome to Orebit/index.html#why-choose-orbit",
    "href": "posts/Welcome to Orebit/index.html#why-choose-orbit",
    "title": "Welcome to Orbit: Open-Source Geological Analysis Tools",
    "section": "Why Choose Orbit?",
    "text": "Why Choose Orbit?\nCost-Effective: Enterprise capabilities without enterprise costs\nTransparent: Complete visibility into analytical methods\nProfessional: Built by practicing geoscientists for real-world challenges\nAccessible: Cloud-native, runs in any browser"
  },
  {
    "objectID": "posts/Welcome to Orebit/index.html#quick-start-with-r",
    "href": "posts/Welcome to Orebit/index.html#quick-start-with-r",
    "title": "Welcome to Orbit: Open-Source Geological Analysis Tools",
    "section": "Quick Start with R",
    "text": "Quick Start with R\nOrbit applications are built with R. Here’s a simple example of geological data visualization:\n\nlibrary(tidyverse)\nlibrary(plotly)\n\n# Sample drillhole data\ncollar_data &lt;- tibble(\n  HoleID = paste0(\"DH\", 1:20),\n  X = runif(20, 100, 500),\n  Y = runif(20, 100, 500),\n  Z = runif(20, 50, 200),\n  Grade = rlnorm(20, 0, 0.5)\n)\n\n# Interactive 3D visualization\nplot_ly(collar_data, x = ~X, y = ~Y, z = ~Z, \n        color = ~Grade, type = 'scatter3d', mode = 'markers',\n        marker = list(size = 8, colorscale = 'Viridis'),\n        text = ~paste(\"Hole:\", HoleID, \"&lt;br&gt;Grade:\", round(Grade, 2))) %&gt;%\n  layout(title = \"Drillhole Collar Map\",\n         scene = list(\n           xaxis = list(title = \"Easting\"),\n           yaxis = list(title = \"Northing\"),\n           zaxis = list(title = \"Elevation\")\n         ))"
  },
  {
    "objectID": "posts/Welcome to Orebit/index.html#learning-resources",
    "href": "posts/Welcome to Orebit/index.html#learning-resources",
    "title": "Welcome to Orbit: Open-Source Geological Analysis Tools",
    "section": "Learning Resources",
    "text": "Learning Resources\n\nTechnical Blog\nComprehensive guides on: - Exploratory data analysis workflows - Data preprocessing techniques - Geostatistical modeling - Resource estimation best practices\n\n\nCommunity\n\nGitHub: github.com/orbit-geo\nLinkedIn: Professional networking and updates\nInstagram: @orebit.id - Visual tutorials"
  },
  {
    "objectID": "posts/Welcome to Orebit/index.html#get-started",
    "href": "posts/Welcome to Orebit/index.html#get-started",
    "title": "Welcome to Orbit: Open-Source Geological Analysis Tools",
    "section": "Get Started",
    "text": "Get Started\nFor Individuals: Try GeoDataViz demo and explore tutorials\nFor Companies: Contact us for enterprise deployment\nFor Developers: Contribute to open-source development\nLaunch GeoDataViz View Documentation\n\nOrbit Geological Solutions - Making professional geological analysis accessible to everyone."
  },
  {
    "objectID": "posts/Drillhole Data Preprocessing/index.html",
    "href": "posts/Drillhole Data Preprocessing/index.html",
    "title": "Pre-Processing Drillhole Data for Resource Estimation",
    "section": "",
    "text": "Poor preprocessing = Poor resource estimates\nPreprocessing failures account for most resource estimation errors: - 30% grade overestimation from wrong composite lengths - Domain boundary failures creating artificial continuity - Outlier treatment errors causing bias"
  },
  {
    "objectID": "posts/Drillhole Data Preprocessing/index.html#why-preprocessing-matters",
    "href": "posts/Drillhole Data Preprocessing/index.html#why-preprocessing-matters",
    "title": "Pre-Processing Drillhole Data for Resource Estimation",
    "section": "",
    "text": "Poor preprocessing = Poor resource estimates\nPreprocessing failures account for most resource estimation errors: - 30% grade overestimation from wrong composite lengths - Domain boundary failures creating artificial continuity - Outlier treatment errors causing bias"
  },
  {
    "objectID": "posts/Drillhole Data Preprocessing/index.html#the-4-step-preprocessing-workflow",
    "href": "posts/Drillhole Data Preprocessing/index.html#the-4-step-preprocessing-workflow",
    "title": "Pre-Processing Drillhole Data for Resource Estimation",
    "section": "The 4-Step Preprocessing Workflow",
    "text": "The 4-Step Preprocessing Workflow\n\nStep 1: Desurveying\nTransform survey data into 3D coordinates:\n\nlibrary(tidyverse)\nlibrary(plotly)\n\n# Sample data\ncollar &lt;- tibble(\n  HoleID = \"DH001\",\n  X = 1000, Y = 2000, Z = 500\n)\n\nsurvey &lt;- tibble(\n  HoleID = \"DH001\",\n  Depth = c(0, 50, 100, 150),\n  Azimuth = c(0, 0, 5, 10),\n  Dip = c(-90, -85, -80, -75)\n)\n\nassay &lt;- tibble(\n  HoleID = \"DH001\",\n  From = seq(0, 145, 5),\n  To = seq(5, 150, 5),\n  Grade = rlnorm(30, meanlog = 0.3, sdlog = 0.6)\n)\n\n# Desurveying function\ndesurvey_hole &lt;- function(collar, survey, assay) {\n  \n  # Interpolate survey at sample midpoints\n  assay_3d &lt;- assay %&gt;%\n    mutate(\n      Midpoint = (From + To) / 2,\n      # Find survey interval\n      Survey_Idx = findInterval(Midpoint, survey$Depth),\n      # Get survey values\n      Azimuth = survey$Azimuth[pmin(Survey_Idx + 1, nrow(survey))],\n      Dip = survey$Dip[pmin(Survey_Idx + 1, nrow(survey))],\n      # Convert to radians\n      Az_rad = Azimuth * pi / 180,\n      Dip_rad = Dip * pi / 180,\n      # Calculate displacement\n      Length = To - From,\n      DX = Length * sin(Az_rad) * cos(Dip_rad),\n      DY = Length * cos(Az_rad) * cos(Dip_rad),\n      DZ = Length * sin(Dip_rad)\n    ) %&gt;%\n    mutate(\n      # Calculate cumulative coordinates\n      X = collar$X + cumsum(DX),\n      Y = collar$Y + cumsum(DY),\n      Z = collar$Z + cumsum(DZ)\n    )\n  \n  return(assay_3d)\n}\n\n# Apply desurveying\ndesurveyed &lt;- desurvey_hole(collar, survey, assay)\n\n# Visualize\nplot_ly(desurveyed, x = ~X, y = ~Y, z = ~Z,\n        color = ~Grade, type = 'scatter3d', mode = 'markers',\n        marker = list(size = 5, colorscale = 'Viridis', \n                     colorbar = list(title = \"Grade\"))) %&gt;%\n  layout(title = \"Desurveyed Drillhole\",\n         scene = list(\n           xaxis = list(title = \"X\"),\n           yaxis = list(title = \"Y\"),\n           zaxis = list(title = \"Z\", autorange = \"reversed\")\n         ))\n\n\n\n\n\n\n\nStep 2: Compositing\nRegularize sample lengths:\n\n# Compositing function (5m length)\ncomposite_data &lt;- function(data, comp_length = 5) {\n  \n  composites &lt;- data %&gt;%\n    mutate(\n      # Assign composite interval\n      Comp_ID = floor(From / comp_length)\n    ) %&gt;%\n    group_by(Comp_ID) %&gt;%\n    summarise(\n      From = min(From),\n      To = max(To),\n      Length = To - From,\n      Grade = weighted.mean(Grade, To - From),\n      X = mean(X),\n      Y = mean(Y),\n      Z = mean(Z),\n      N_Samples = n(),\n      .groups = 'drop'\n    ) %&gt;%\n    filter(Length &gt;= comp_length * 0.5)  # Keep composites &gt; 50% target length\n  \n  return(composites)\n}\n\n# Create composites\ncomposites &lt;- composite_data(desurveyed, comp_length = 5)\n\ncat(\"Original samples:\", nrow(desurveyed), \"\\n\")\n\nOriginal samples: 30 \n\ncat(\"Composites:\", nrow(composites), \"\\n\")\n\nComposites: 30 \n\ncat(\"Average composite length:\", round(mean(composites$Length), 2), \"m\\n\")\n\nAverage composite length: 5 m\n\n# Display\nhead(composites %&gt;% select(Comp_ID, From, To, Length, Grade, X, Y, Z))\n\n# A tibble: 6 × 8\n  Comp_ID  From    To Length Grade     X     Y     Z\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       0     0     5      5  2.36  1000 2000.  495.\n2       1     5    10      5  2.02  1000 2001.  490.\n3       2    10    15      5  3.87  1000 2001.  485.\n4       3    15    20      5  4.15  1000 2002.  480.\n5       4    20    25      5  1.20  1000 2002.  475.\n6       5    25    30      5  3.29  1000 2003.  470.\n\n\nComposite Length Selection: - Too short: Excessive smoothing, lose geological detail - Too long: Sample non-stationarity, poor statistics - Typical: 1-5m for most deposits\n\n\nStep 3: Outlier Treatment\nIdentify and handle extreme values:\n\n# Calculate percentile thresholds\nP95 &lt;- quantile(composites$Grade, 0.95)\nP99 &lt;- quantile(composites$Grade, 0.99)\n\n# Identify outliers\noutlier_summary &lt;- composites %&gt;%\n  summarise(\n    Mean = mean(Grade),\n    Median = median(Grade),\n    P95 = P95,\n    P99 = P99,\n    N_Above_P95 = sum(Grade &gt; P95),\n    N_Above_P99 = sum(Grade &gt; P99)\n  )\n\nprint(outlier_summary)\n\n# A tibble: 1 × 6\n   Mean Median   P95   P99 N_Above_P95 N_Above_P99\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;int&gt;       &lt;int&gt;\n1  1.53   1.19  4.02  4.85           2           1\n\n# Top-cutting demonstration\ncomposites_capped &lt;- composites %&gt;%\n  mutate(\n    Grade_Original = Grade,\n    Grade_Capped = pmin(Grade, P95)  # Cap at 95th percentile\n  )\n\n# Comparison plot\np1 &lt;- plot_ly(composites, x = ~Grade, type = \"histogram\", \n              name = \"Original\", nbinsx = 20) %&gt;%\n  layout(xaxis = list(title = \"Grade\"))\n\np2 &lt;- plot_ly(composites_capped, x = ~Grade_Capped, type = \"histogram\",\n              name = \"Capped (P95)\", nbinsx = 20) %&gt;%\n  layout(xaxis = list(title = \"Grade\"))\n\nsubplot(p1, p2, nrows = 2, shareX = TRUE) %&gt;%\n  layout(title = \"Effect of Grade Capping\")\n\n\n\nOutlier analysis and capping\n\n\nCapping Strategies: - Statistical: Percentile-based (95th, 98th) - Geological: Based on domain/mineralization type - Spatial: Consider outlier distribution\n\n\nStep 4: Domain Assignment\nAssign samples to geological domains:\n\n# Simple domain assignment (by elevation)\ncomposites_domains &lt;- composites %&gt;%\n  mutate(\n    Domain = case_when(\n      Z &gt; 480 ~ \"Oxide\",\n      Z &gt; 460 ~ \"Transition\",\n      TRUE ~ \"Fresh\"\n    )\n  )\n\n# Domain statistics\ndomain_stats &lt;- composites_domains %&gt;%\n  group_by(Domain) %&gt;%\n  summarise(\n    N_Samples = n(),\n    Mean_Grade = mean(Grade),\n    SD_Grade = sd(Grade),\n    Min_Grade = min(Grade),\n    Max_Grade = max(Grade),\n    .groups = 'drop'\n  )\n\nprint(domain_stats)\n\n# A tibble: 3 × 6\n  Domain     N_Samples Mean_Grade SD_Grade Min_Grade Max_Grade\n  &lt;chr&gt;          &lt;int&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 Fresh             22       1.05    0.490     0.195      2.26\n2 Oxide              4       3.10    1.07      2.02       4.15\n3 Transition         4       2.61    2.00      0.829      5.14\n\n# Visualize domains\nplot_ly(composites_domains, x = ~X, y = ~Y, z = ~Z,\n        color = ~Domain, colors = c(\"orange\", \"yellow\", \"green\"),\n        type = 'scatter3d', mode = 'markers',\n        marker = list(size = 5)) %&gt;%\n  layout(title = \"Geological Domains\",\n         scene = list(\n           xaxis = list(title = \"X\"),\n           yaxis = list(title = \"Y\"),\n           zaxis = list(title = \"Z\", autorange = \"reversed\")\n         ))"
  },
  {
    "objectID": "posts/Drillhole Data Preprocessing/index.html#quality-checks-before-estimation",
    "href": "posts/Drillhole Data Preprocessing/index.html#quality-checks-before-estimation",
    "title": "Pre-Processing Drillhole Data for Resource Estimation",
    "section": "Quality Checks Before Estimation",
    "text": "Quality Checks Before Estimation\n\nChecklist:\n\n# Automated QA checks\nqa_results &lt;- list(\n  \"Total composites\" = nrow(composites),\n  \"Composite length CV\" = round(sd(composites$Length)/mean(composites$Length), 2),\n  \"Grade CV\" = round(sd(composites$Grade)/mean(composites$Grade), 2),\n  \"Domains defined\" = n_distinct(composites_domains$Domain),\n  \"Outliers (&gt;P95)\" = sum(composites$Grade &gt; P95),\n  \"Missing coords\" = sum(is.na(composites$X) | is.na(composites$Y) | is.na(composites$Z))\n)\n\ncat(\"QA/QC Summary:\\n\")\n\nQA/QC Summary:\n\nfor(i in seq_along(qa_results)) {\n  cat(sprintf(\"- %s: %s\\n\", names(qa_results)[i], qa_results[[i]]))\n}\n\n- Total composites: 30\n- Composite length CV: 0\n- Grade CV: 0.77\n- Domains defined: 3\n- Outliers (&gt;P95): 2\n- Missing coords: 0\n\n\nPass Criteria: - [ ] Composite length CV &lt; 0.3 - [ ] All coordinates valid - [ ] Outliers documented and justified - [ ] Domains statistically different"
  },
  {
    "objectID": "posts/Drillhole Data Preprocessing/index.html#using-geodataviz-for-preprocessing",
    "href": "posts/Drillhole Data Preprocessing/index.html#using-geodataviz-for-preprocessing",
    "title": "Pre-Processing Drillhole Data for Resource Estimation",
    "section": "Using GeoDataViz for Preprocessing",
    "text": "Using GeoDataViz for Preprocessing\nGeoDataViz automates this entire workflow:\nFeatures: 1. Auto-desurveying: Multiple survey interpolation methods 2. Smart compositing: Geological boundary preservation 3. Outlier detection: Multiple statistical methods 4. Domain tools: Interactive 3D domain definition 5. Export: CSV, Excel, or database formats\nTry GeoDataViz →"
  },
  {
    "objectID": "posts/Drillhole Data Preprocessing/index.html#next-steps",
    "href": "posts/Drillhole Data Preprocessing/index.html#next-steps",
    "title": "Pre-Processing Drillhole Data for Resource Estimation",
    "section": "Next Steps",
    "text": "Next Steps\nAfter preprocessing: 1. Variogram Modeling → Spatial continuity analysis 2. Block Modeling → Create estimation grid 3. Kriging → Resource estimation 4. Validation → Model quality checks\nNext Guide: Coming soon - “Variogram Modeling with GeoDataViz”"
  },
  {
    "objectID": "posts/Drillhole Data Preprocessing/index.html#summary-code",
    "href": "posts/Drillhole Data Preprocessing/index.html#summary-code",
    "title": "Pre-Processing Drillhole Data for Resource Estimation",
    "section": "Summary Code",
    "text": "Summary Code\nComplete preprocessing pipeline:\n\n# Complete workflow\npreprocessing_pipeline &lt;- function(collar, survey, assay, comp_length = 5) {\n  \n  # 1. Desurvey\n  desurveyed &lt;- desurvey_hole(collar, survey, assay)\n  \n  # 2. Composite\n  composites &lt;- composite_data(desurveyed, comp_length)\n  \n  # 3. Cap outliers\n  P95 &lt;- quantile(composites$Grade, 0.95)\n  composites$Grade_Capped &lt;- pmin(composites$Grade, P95)\n  \n  # 4. Assign domains\n  composites$Domain &lt;- case_when(\n    composites$Z &gt; 480 ~ \"Oxide\",\n    composites$Z &gt; 460 ~ \"Transition\",\n    TRUE ~ \"Fresh\"\n  )\n  \n  return(composites)\n}\n\n\nFor step-by-step video tutorials, visit @orebit.id"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Technical Resources",
    "section": "",
    "text": "Welcome to the Orebit Knowledge Hub\n\n\nHere you’ll find in-depth articles, practical tutorials, and case studies designed to help you master modern geological data analysis. Whether you’re using our flagship application, GeoDataViz, or exploring advanced open-source workflows in R, these resources are here to support your work.\n\n\n\n\n\n\n\n\n   \n    \n    \n      Urut berdasar\n      Default\n      \n        Judul\n      \n      \n        Tanggal - Paling lama\n      \n      \n        Tanggal - Paling baru\n      \n      \n        Penulis\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nPre-Processing Drillhole Data for Resource Estimation\n\n\n\nGeoDataViz\n\nPreprocessing\n\nResource-Estimation\n\n\n\nComplete workflow for transforming raw drillhole data into estimation-ready datasets using R.\n\n\n\nGhozian Islam Karami\n\n\n20 Sep 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis for Geological Data with GeoDataViz\n\n\n\nGeoDataViz\n\nEDA\n\nTutorial\n\n\n\nPractical guide to exploratory data analysis for geological datasets using R and GeoDataViz workflows.\n\n\n\nGhozian Islam Karami\n\n\n20 Sep 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to Orbit: Open-Source Geological Analysis Tools\n\n\n\nWelcome\n\nOpen-Source\n\nGeoDataViz\n\n\n\nDiscover Orbit’s suite of R Shiny applications for geological data analysis - from exploration to resource estimation.\n\n\n\nGhozian Islam Karami\n\n\n20 Sep 2025\n\n\n\n\n\n\nTidak ada yang cocok"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Orebit",
    "section": "",
    "text": "Orebit Geological Solutions develops professional R Shiny applications that transform how geoscientists and mining engineers approach data analysis. Our mission is to provide cost-effective, transparent, and powerful analytical tools that rival expensive proprietary software—without the prohibitive licensing fees."
  },
  {
    "objectID": "about.html#advanced-geological-solutions-for-the-modern-mining-industry",
    "href": "about.html#advanced-geological-solutions-for-the-modern-mining-industry",
    "title": "About Orebit",
    "section": "",
    "text": "Orebit Geological Solutions develops professional R Shiny applications that transform how geoscientists and mining engineers approach data analysis. Our mission is to provide cost-effective, transparent, and powerful analytical tools that rival expensive proprietary software—without the prohibitive licensing fees."
  },
  {
    "objectID": "about.html#the-challenge-we-address",
    "href": "about.html#the-challenge-we-address",
    "title": "About Orebit",
    "section": "The Challenge We Address",
    "text": "The Challenge We Address\nThe mining industry faces a critical paradox: geological analysis demands increasingly sophisticated tools, yet traditional software solutions create barriers through:\n\nHigh Costs: Enterprise geological software can exceed $50,000 per year in licensing fees\nVendor Lock-in: Proprietary systems limit flexibility and customization\nLimited Transparency: Black-box algorithms make validation and reproducibility difficult\nAccessibility Gaps: Small companies and consultants struggle to afford industry-standard tools\n\nOrebit exists to eliminate these barriers."
  },
  {
    "objectID": "about.html#our-product-philosophy",
    "href": "about.html#our-product-philosophy",
    "title": "About Orebit",
    "section": "Our Product Philosophy",
    "text": "Our Product Philosophy\n\nOpen-Source Foundation\nAll Orebit applications are built on open-source technologies, ensuring: - Complete transparency in analytical methods - Full reproducibility of results - No vendor lock-in or hidden dependencies - Community-driven development and improvement\n\n\nUniversal Accessibility\nCloud-native architecture means: - No installation required - Run directly in web browsers - Access from anywhere - Cross-platform compatibility"
  },
  {
    "objectID": "about.html#the-team-behind-orebit",
    "href": "about.html#the-team-behind-orebit",
    "title": "About Orebit",
    "section": "The Team Behind Orebit",
    "text": "The Team Behind Orebit\nOrebit is led by Ghozian Islam Karami, Senior Geologist and Certified BNSP Competent Person (CP) with over a decade of mining industry experience. His expertise in offshore tin exploration, resource evaluation, and geological data analysis ensures that every Orebit application addresses real-world geological challenges.\nCore Expertise: - Geostatistics and resource modeling - R programming and Shiny application development - Quality assurance systems for mining operations - Geospatial analysis and 3D geological modeling\nProfessional Credentials: - Certified Competent Person (CP) - BNSP - M.Sc. Geological Sciences - KFUPM - B.Sc. Geology - Universitas Padjadjaran - Senior Geologist - PERHAPI\nThis combination of geological expertise and technical development skills ensures Orebit applications are both geologically sound and technically sophisticated."
  },
  {
    "objectID": "about.html#contact-information",
    "href": "about.html#contact-information",
    "title": "About Orebit",
    "section": "Contact Information",
    "text": "Contact Information\nEmail: ghoziankarami@gmail.com\nGitHub: github.com/ghoziankarami\nLinkedIn: Ghozian Islam Karami"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Digitizing Geology, From Exploration to Production",
    "section": "",
    "text": "Professional R Shiny applications for modern geology. We provide an advanced geological analysis suite—including GeoDataViz, Resource Estimation, and Pit Optimization tools—for professional geoscientists and mining engineers. Built by geologists, for geologists.\n\n Launch GeoDataViz Demo  Read Technical Guides\n\n\n\n\nAccess enterprise-level tools without the enterprise-level costs. We bridge the gap between powerful analytics and accessibility.\n\n\n\n\n\n\n\nEliminate prohibitive $20,000+ annual licensing fees. Powerful tools should be accessible to all, not just the largest corporations.\n\n\n\n\n\n\n\n\nDeveloped by a Certified Competent Person (CP) who understands the real-world challenges and workflows of the mining industry.\n\n\n\n\n\n\n\n\nBuilt on open-source R technology. No black-box algorithms. Our methods are clear, ensuring reproducibility and scientific integrity.\n\n\n\n\n\n\n\n\nNo installation, no maintenance. Run sophisticated analyses directly in your browser, anywhere, on any device.\n\n\n\n\n\n\n\n\n\n\nAvailable Now\n\nTransform your geological workflow with professional-grade exploratory data analysis and 3D visualization, built specifically for drillhole datasets. Launch Free Demo →\n\n\n\n\nComing Q2 2026\n\nProfessional geostatistical analysis and resource modeling. Advanced kriging, variogram modeling, and uncertainty quantification. Join Beta List →\n\n\n\n\nComing Q3 2026\n\nSophisticated mine planning and optimization algorithms. Maximize NPV while considering operational constraints and environmental factors. Get Notified →\n\n\n\n\n\n\nStay updated on our upcoming resource estimation and pit optimization tools.\n\n Get Notified"
  },
  {
    "objectID": "index.html#why-orebit-solutions",
    "href": "index.html#why-orebit-solutions",
    "title": "Digitizing Geology, From Exploration to Production",
    "section": "",
    "text": "Access enterprise-level tools without the enterprise-level costs. We bridge the gap between powerful analytics and accessibility.\n\n\n\n\n\n\n\nEliminate prohibitive $20,000+ annual licensing fees. Powerful tools should be accessible to all, not just the largest corporations.\n\n\n\n\n\n\n\n\nDeveloped by a Certified Competent Person (CP) who understands the real-world challenges and workflows of the mining industry.\n\n\n\n\n\n\n\n\nBuilt on open-source R technology. No black-box algorithms. Our methods are clear, ensuring reproducibility and scientific integrity.\n\n\n\n\n\n\n\n\nNo installation, no maintenance. Run sophisticated analyses directly in your browser, anywhere, on any device."
  },
  {
    "objectID": "posts/EDA with GeoDataViz/index.html",
    "href": "posts/EDA with GeoDataViz/index.html",
    "title": "Exploratory Data Analysis for Geological Data with GeoDataViz",
    "section": "",
    "text": "Inadequate exploratory data analysis is the primary cause of flawed resource models. Before resource estimation, you must understand:\n\nData quality and completeness\nStatistical distributions\nSpatial patterns and bias\nGeological domains\nOutlier populations"
  },
  {
    "objectID": "posts/EDA with GeoDataViz/index.html#why-eda-matters",
    "href": "posts/EDA with GeoDataViz/index.html#why-eda-matters",
    "title": "Exploratory Data Analysis for Geological Data with GeoDataViz",
    "section": "",
    "text": "Inadequate exploratory data analysis is the primary cause of flawed resource models. Before resource estimation, you must understand:\n\nData quality and completeness\nStatistical distributions\nSpatial patterns and bias\nGeological domains\nOutlier populations"
  },
  {
    "objectID": "posts/EDA with GeoDataViz/index.html#the-5-phase-eda-workflow",
    "href": "posts/EDA with GeoDataViz/index.html#the-5-phase-eda-workflow",
    "title": "Exploratory Data Analysis for Geological Data with GeoDataViz",
    "section": "The 5-Phase EDA Workflow",
    "text": "The 5-Phase EDA Workflow\n\nPhase 1: Data Validation\nFirst, check data integrity:\n\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(DT)\n\n# Sample drillhole data\nset.seed(123)\ndrillhole_data &lt;- tibble(\n  HoleID = rep(paste0(\"DH\", 1:10), each = 10),\n  From = rep(seq(0, 90, 10), 10),\n  To = rep(seq(10, 100, 10), 10),\n  Grade = rlnorm(100, meanlog = 0.5, sdlog = 0.8),\n  X = rep(runif(10, 100, 200), each = 10),\n  Y = rep(runif(10, 100, 200), each = 10),\n  Z = rep(seq(50, 95, 5), 10)\n)\n\n# Data summary\ncat(\"Total samples:\", nrow(drillhole_data), \"\\n\")\n\nTotal samples: 100 \n\ncat(\"Unique holes:\", n_distinct(drillhole_data$HoleID), \"\\n\")\n\nUnique holes: 10 \n\ncat(\"Grade range:\", round(min(drillhole_data$Grade), 2), \"-\", \n    round(max(drillhole_data$Grade), 2), \"\\n\")\n\nGrade range: 0.26 - 9.49 \n\n\n\n\nPhase 2: Statistical Analysis\nUnderstand grade distribution:\n\n# Summary statistics\nsummary_stats &lt;- drillhole_data %&gt;%\n  summarise(\n    Mean = mean(Grade),\n    Median = median(Grade),\n    SD = sd(Grade),\n    CV = sd(Grade)/mean(Grade),\n    Skewness = moments::skewness(Grade)\n  )\n\nprint(summary_stats)\n\n# A tibble: 1 × 5\n   Mean Median    SD    CV Skewness\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1  2.31   1.73  1.86 0.805     1.90\n\n# Histogram and boxplot\np1 &lt;- plot_ly(drillhole_data, x = ~Grade, type = \"histogram\", \n              nbinsx = 30, name = \"Distribution\") %&gt;%\n  layout(xaxis = list(title = \"Grade\"), \n         yaxis = list(title = \"Frequency\"))\n\np2 &lt;- plot_ly(drillhole_data, y = ~Grade, type = \"box\", \n              name = \"Boxplot\") %&gt;%\n  layout(yaxis = list(title = \"Grade\"))\n\nsubplot(p1, p2, nrows = 1, shareY = FALSE, titleX = TRUE) %&gt;%\n  layout(title = \"Grade Distribution Analysis\")\n\n\n\n\n\n\n\nGambar 1: Grade distribution analysis\n\n\n\n\nKey Observations: - Check for skewness (common in geological data) - Identify outliers using boxplot - Assess if transformation needed\n\n\nPhase 3: Spatial Analysis\nVisualize spatial patterns:\n\n# Calculate average grade per hole\ncollar_summary &lt;- drillhole_data %&gt;%\n  group_by(HoleID, X, Y) %&gt;%\n  summarise(\n    AvgGrade = mean(Grade),\n    MaxGrade = max(Grade),\n    .groups = 'drop'\n  )\n\n# Interactive map\nplot_ly(collar_summary, x = ~X, y = ~Y, color = ~AvgGrade,\n        type = 'scatter', mode = 'markers',\n        marker = list(size = 15, colorscale = 'Viridis', \n                     showscale = TRUE, colorbar = list(title = \"Grade\")),\n        text = ~paste(\"Hole:\", HoleID, \n                     \"&lt;br&gt;Avg Grade:\", round(AvgGrade, 2))) %&gt;%\n  layout(title = \"Drillhole Collar Map\",\n         xaxis = list(title = \"Easting (X)\"),\n         yaxis = list(title = \"Northing (Y)\"))\n\n\n\n\n\n\n\nGambar 2: Spatial distribution of drillholes\n\n\n\n\nWhat to Look For: - High-grade clustering - Spatial trends - Drilling density variations - Potential bias in sampling\n\n\nPhase 4: Outlier Analysis\nIdentify and understand outliers:\n\n# Calculate IQR method thresholds\nQ1 &lt;- quantile(drillhole_data$Grade, 0.25)\nQ3 &lt;- quantile(drillhole_data$Grade, 0.75)\nIQR &lt;- Q3 - Q1\n\nlower_bound &lt;- Q1 - 1.5 * IQR\nupper_bound &lt;- Q3 + 1.5 * IQR\n\n# Identify outliers\noutliers &lt;- drillhole_data %&gt;%\n  filter(Grade &gt; upper_bound | Grade &lt; lower_bound) %&gt;%\n  arrange(desc(Grade))\n\ncat(\"Number of outliers:\", nrow(outliers), \"\\n\")\n\nNumber of outliers: 8 \n\ncat(\"Outlier threshold:\", round(upper_bound, 2), \"\\n\")\n\nOutlier threshold: 5.5 \n\ncat(\"Top 5 outliers:\\n\")\n\nTop 5 outliers:\n\nprint(head(outliers %&gt;% select(HoleID, From, To, Grade), 5))\n\n# A tibble: 5 × 4\n  HoleID  From    To Grade\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 DH10      60    70  9.49\n2 DH5       30    40  9.35\n3 DH7       90   100  8.50\n4 DH2       50    60  6.89\n5 DH1       50    60  6.50\n\n\nDecision Points: - Are outliers geologically valid? - Do they represent high-grade zones? - Should they be capped or modeled separately?\n\n\nPhase 5: 3D Visualization\nVisualize geological context:\n\n# Create 3D visualization\nplot_ly(drillhole_data, x = ~X, y = ~Y, z = ~Z,\n        color = ~Grade, type = 'scatter3d', mode = 'markers',\n        marker = list(size = 3, colorscale = 'Viridis',\n                     showscale = TRUE, colorbar = list(title = \"Grade\")),\n        text = ~paste(\"Hole:\", HoleID, \n                     \"&lt;br&gt;Depth:\", From, \"-\", To,\n                     \"&lt;br&gt;Grade:\", round(Grade, 2))) %&gt;%\n  layout(title = \"3D Drillhole View\",\n         scene = list(\n           xaxis = list(title = \"Easting\"),\n           yaxis = list(title = \"Northing\"),\n           zaxis = list(title = \"Elevation\", autorange = \"reversed\")\n         ))\n\n\n\n\n\n\n\nGambar 3: 3D drillhole visualization"
  },
  {
    "objectID": "posts/EDA with GeoDataViz/index.html#quick-eda-checklist",
    "href": "posts/EDA with GeoDataViz/index.html#quick-eda-checklist",
    "title": "Exploratory Data Analysis for Geological Data with GeoDataViz",
    "section": "Quick EDA Checklist",
    "text": "Quick EDA Checklist\nBefore proceeding to resource estimation:\n\nData validated (no gaps, coordinates correct)\nStatistical distribution understood\nOutliers identified and assessed\nSpatial patterns reviewed\nGeological domains preliminary defined\nQA/QC results reviewed"
  },
  {
    "objectID": "posts/EDA with GeoDataViz/index.html#using-geodataviz",
    "href": "posts/EDA with GeoDataViz/index.html#using-geodataviz",
    "title": "Exploratory Data Analysis for Geological Data with GeoDataViz",
    "section": "Using GeoDataViz",
    "text": "Using GeoDataViz\nAll these analyses can be performed interactively in GeoDataViz:\n\nUpload Data: CSV/Excel with collar, survey, assay tables\nAuto-Validation: Instant data quality report\nInteractive EDA: Click-and-explore interface\nExport Results: PDF reports and processed data\n\nTry GeoDataViz Demo →"
  },
  {
    "objectID": "posts/EDA with GeoDataViz/index.html#next-steps",
    "href": "posts/EDA with GeoDataViz/index.html#next-steps",
    "title": "Exploratory Data Analysis for Geological Data with GeoDataViz",
    "section": "Next Steps",
    "text": "Next Steps\nAfter completing EDA: 1. Data Preprocessing: Compositing and domain definition 2. Variogram Modeling: Spatial continuity analysis 3. Resource Estimation: Block modeling and kriging\nNext Guide: Pre-Processing Drillhole Data →\n\nFor visual tutorials on these techniques, check @orebit.id on Instagram."
  }
]